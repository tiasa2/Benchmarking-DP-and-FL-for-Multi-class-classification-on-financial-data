{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_financial_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAC33tfJDZhe",
        "outputId": "4d119442-b80a-49a8-8e47-54f67ad5fb42"
      },
      "source": [
        "!pip install transformers==3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.62.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZJAwfU3utMH"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "\n",
        "# Use GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmxASPASkkj4",
        "outputId": "f8f2ab31-c61f-4c36-ae4c-d1085b2a7b7a"
      },
      "source": [
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emUOZPJEutbw"
      },
      "source": [
        "f = open(\"/content/Sentences_75Agree.txt\", \"r\", encoding=\"ISO-8859-1\")\n",
        "data = f.readlines()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUo7D_LWlCjw"
      },
      "source": [
        "text = []\n",
        "labels = []\n",
        "for i in range(0,len(data)):\n",
        "  t = data[i].replace('@',' ')\n",
        "  t = t.replace('\\n','')\n",
        "  text.append((' ').join(t.split()[:-1]))\n",
        "  labels.append(t.split()[-1])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWOJmRUHxMf4"
      },
      "source": [
        "for l in range(0,len(labels)):\n",
        "  if labels[l] == 'positive':\n",
        "    labels[l] = 0\n",
        "  elif labels[l] == 'neutral':\n",
        "    labels[l] = 1\n",
        "  elif labels[l] == 'negative':\n",
        "    labels[l] = 2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbgSVMIyuxeA"
      },
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(text, labels, \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                    stratify=labels)\n",
        "\n",
        "# Using temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.1, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrIzvsJpu2UN"
      },
      "source": [
        "# Importing ROBERTA-base pretrained model\n",
        "roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the ROBERTA tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDK7qeXcu5BG",
        "outputId": "15499b7a-a0b7-4046-cf6d-31f0999815e7"
      },
      "source": [
        "# Sample data\n",
        "txt = [\"this is a robert model tutorial\", \"we will fine-tune a robert model\"]\n",
        "\n",
        "# Encode text\n",
        "sent_id = tokenizer.batch_encode_plus(txt, padding=True, return_token_type_ids=False)\n",
        "\n",
        "# Output\n",
        "print(sent_id)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[0, 9226, 16, 10, 4533, 6747, 1421, 35950, 2, 1, 1, 1], [0, 1694, 40, 2051, 12, 90, 4438, 10, 4533, 6747, 1421, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "d_Z0bPs_vHFc",
        "outputId": "f5ffcc5a-17e4-4bb5-ceb7-e5c0a39234f9"
      },
      "source": [
        "# Getting length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f95b3d0e550>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWAklEQVR4nO3df4xdZZ3H8fdHflkZ08KCN7VttmyoGmTWQieA0WxmYF0BNxYTl0CIFmV33AR3cdPsUtxkhXVJalZk/RWSuiBVWUYWcdvUn1g7a9gsYEcr01JZq1RlUlsVqA6wxMHv/nGfrpdhZu6Zub+ePnxeyc2c85znnvu599z5zrnPPeeMIgIzMyvLS3odwMzM2s/F3cysQC7uZmYFcnE3MyuQi7uZWYGO7XUAgFNOOSVWrlw56/KnnnqKE088sXuBKso1F+SbLddckG+2XHNBvtlyzQXtzTY2NvaLiDh1xoUR0fPbmjVrYi47duyYc3mv5JorIt9sueaKyDdbrrki8s2Wa66I9mYDdsYsddXDMmZmBXJxNzMrkIu7mVmBXNzNzArk4m5mViAXdzOzArm4m5kVyMXdzKxATYu7pJdKelDS9yTtkXRDar9d0qOSdqXb6tQuSR+TtE/SQ5LO7vSTMDOz56ty+YFngfMjYlLSccB9kr6Slv1tRNw9rf9FwKp0Oxe4Jf20Nlm54UtN+6zvn2Kw81HMLFNN99zTWa6Tafa4dJvr3zetBT6T7nc/sETS0tajmplZVYoK/2ZP0jHAGHA68MmIuFbS7cDrqe/Zbwc2RMSzkrYBGyPivnTf7cC1EbFz2jqHgWGAWq22ZmRkZNbHn5ycpK+vbwFPr7N6lWt84nDTPrVF8IqTF3chzfzkui0h32y55oJ8s+WaC9qbbWhoaCwiBmZaVumqkBHxHLBa0hLgi5LOBK4DfgYcD2wCrgX+sWqoiNiU7sfAwEAMDg7O2nd0dJS5lvdKr3JdWXFY5lK/ZvOSa7Zcc0G+2XLNBd3LNq+jZSLiSWAHcGFEHEhDL88CnwbOSd0mgBUNd1ue2szMrEuqHC1zatpjR9Ii4E3A94+Mo0sScAmwO91lK/DOdNTMecDhiDjQkfRmZjajKsMyS4HNadz9JcBdEbFN0jclnQoI2AX8Zer/ZeBiYB/wNPCu9sc2M7O5NC3uEfEQcNYM7efP0j+Aq1uPZmZmC+UzVM3MCuTibmZWIBd3M7MCubibmRXIxd3MrECVzlC11lS50BfA/o1v6XASM3ux8J67mVmBXNzNzArk4m5mViAXdzOzAvkL1YJV/SIX/GWuWWm8525mViAXdzOzArm4m5kVyMXdzKxALu5mZgVycTczK5CLu5lZgVzczcwK5OJuZlagpsVd0kslPSjpe5L2SLohtZ8m6QFJ+yR9XtLxqf2ENL8vLV/Z2adgZmbTVdlzfxY4PyJeB6wGLpR0HvAh4OaIOB14Argq9b8KeCK135z6mZlZFzUt7lE3mWaPS7cAzgfuTu2bgUvS9No0T1p+gSS1LbGZmTWliGjeSToGGANOBz4J/DNwf9o7R9IK4CsRcaak3cCFEfFYWvZD4NyI+MW0dQ4DwwC1Wm3NyMjIrI8/OTlJX1/fAp5eZ1XNNT5xuNL6+pctrtSvyvpqi+DgM5VWN6/HblWu2xLyzZZrLsg3W665oL3ZhoaGxiJiYKZlla4KGRHPAaslLQG+CLym1VARsQnYBDAwMBCDg4Oz9h0dHWWu5b1SNdeVVf/N3hXN11V1fev7p7hpvPpFP6s+dqty3ZaQb7Zcc0G+2XLNBd3LNq+jZSLiSWAH8HpgiaQj1WM5MJGmJ4AVAGn5YuCXbUlrZmaVVDla5tS0x46kRcCbgL3Ui/zbU7d1wJY0vTXNk5Z/M6qM/ZiZWdtU+dy+FNicxt1fAtwVEdskPQyMSPon4LvAran/rcBnJe0DHgcu60BuMzObQ9PiHhEPAWfN0P4j4JwZ2v8X+LO2pDMzswXxGapmZgVycTczK5CLu5lZgVzczcwK5OJuZlYgF3czswK5uJuZFcjF3cysQC7uZmYFcnE3MyuQi7uZWYFc3M3MCuTibmZWIBd3M7MCubibmRXIxd3MrEAu7mZmBXJxNzMrkIu7mVmBXNzNzArUtLhLWiFph6SHJe2RdE1qv17ShKRd6XZxw32uk7RP0iOS3tzJJ2BmZi90bIU+U8D6iPiOpJcDY5LuTctujogPN3aWdAZwGfBa4JXANyS9KiKea2dwMzObXdPiHhEHgANp+teS9gLL5rjLWmAkIp4FHpW0DzgH+O825M3K+MRhrtzwpV7HMDN7gXmNuUtaCZwFPJCa3ivpIUm3SToptS0Dftpwt8eY+4+BmZm1mSKiWkepD/hP4MaIuEdSDfgFEMAHgaUR8W5JnwDuj4jPpfvdCnwlIu6etr5hYBigVqutGRkZmfWxJycn6evrm/eT67RDjx/m4DPtW1//ssWV+o1PHG7ap7aIeWWr+titynVbQr7Zcs0F+WbLNRe0N9vQ0NBYRAzMtKzKmDuSjgO+ANwREfcARMTBhuWfAral2QlgRcPdl6e254mITcAmgIGBgRgcHJz18UdHR5lrea98/I4t3DRe6SWsZvypih2bP+b6/ql5Zdt/xWDlvq3IdVtCvtlyzQX5Zss1F3QvW5WjZQTcCuyNiI80tC9t6PY2YHea3gpcJukESacBq4AH2xfZzMyaqbJr9wbgHcC4pF2p7f3A5ZJWUx+W2Q+8ByAi9ki6C3iY+pE2V/tIGTOz7qpytMx9gGZY9OU57nMjcGMLuczMrAU+Q9XMrEAu7mZmBWrjoR72YrCy4klb+ze+pcNJzGwu3nM3MyuQi7uZWYFc3M3MCuTibmZWIBd3M7MCubibmRXIxd3MrEAu7mZmBXJxNzMrkIu7mVmBXNzNzArk4m5mViAXdzOzArm4m5kVyMXdzKxALu5mZgVycTczK5CLu5lZgZoWd0krJO2Q9LCkPZKuSe0nS7pX0g/Sz5NSuyR9TNI+SQ9JOrvTT8LMzJ6vyp77FLA+Is4AzgOulnQGsAHYHhGrgO1pHuAiYFW6DQO3tD21mZnNqWlxj4gDEfGdNP1rYC+wDFgLbE7dNgOXpOm1wGei7n5giaSlbU9uZmazUkRU7yytBL4FnAn8JCKWpHYBT0TEEknbgI0RcV9ath24NiJ2TlvXMPU9e2q12pqRkZFZH3dycpK+vr55PK3uOPT4YQ4+0+sUM6stYl7Z+pctrtRvfOJwS+vLdVtCvtlyzQX5Zss1F7Q329DQ0FhEDMy07NiqK5HUB3wBeF9E/Kpez+siIiRV/ytRv88mYBPAwMBADA4Oztp3dHSUuZb3ysfv2MJN45Vfwq5a3z81r2z7rxis1O/KDV9qaX25bkvIN1uuuSDfbLnmgu5lq3S0jKTjqBf2OyLintR88MhwS/p5KLVPACsa7r48tZmZWZdUOVpGwK3A3oj4SMOircC6NL0O2NLQ/s501Mx5wOGIONDGzGZm1kSVz+1vAN4BjEvaldreD2wE7pJ0FfBj4NK07MvAxcA+4GngXW1NbGZmTTUt7umLUc2y+IIZ+gdwdYu5zMysBT5D1cysQC7uZmYFcnE3MyuQi7uZWYHyPAPHum5lxZOTzOzo4D13M7MCubibmRXIxd3MrEAu7mZmBXJxNzMrkIu7mVmBXNzNzArk4m5mViAXdzOzArm4m5kVyMXdzKxALu5mZgVycTczK5CLu5lZgVzczcwK1LS4S7pN0iFJuxvarpc0IWlXul3csOw6SfskPSLpzZ0KbmZms6vyzzpuBz4BfGZa+80R8eHGBklnAJcBrwVeCXxD0qsi4rk2ZLUCVf0nIfs3vqXDSczK0nTPPSK+BTxecX1rgZGIeDYiHgX2Aee0kM/MzBZAEdG8k7QS2BYRZ6b564ErgV8BO4H1EfGEpE8A90fE51K/W4GvRMTdM6xzGBgGqNVqa0ZGRmZ9/MnJSfr6+ubzvLri0OOHOfhMr1PMrLaInmbrX7Z4xvbp23J84nBL62unXN9nueaCfLPlmgvam21oaGgsIgZmWrbQ/6F6C/BBINLPm4B3z2cFEbEJ2AQwMDAQg4ODs/YdHR1lruW98vE7tnDTeJ7/hnZ9/1RPs+2/YnDG9unb8sqqwzKzrK+dcn2f5ZoL8s2Way7oXrYFHS0TEQcj4rmI+C3wKX439DIBrGjoujy1mZlZFy2ouEta2jD7NuDIkTRbgcsknSDpNGAV8GBrEc3MbL6afm6XdCcwCJwi6THgA8CgpNXUh2X2A+8BiIg9ku4CHgamgKt9pIyZWfc1Le4RcfkMzbfO0f9G4MZWQpmZWWt8hqqZWYFc3M3MCuTibmZWIBd3M7MCubibmRUoz9Mr7ag32wXB1vdPVT4r1cwWznvuZmYFcnE3MyuQi7uZWYFc3M3MCuTibmZWIBd3M7MCubibmRXIxd3MrEAu7mZmBXJxNzMrkC8/YEeF2S5nMN3+jW/pcBKzo4P33M3MCuTibmZWIBd3M7MCNS3ukm6TdEjS7oa2kyXdK+kH6edJqV2SPiZpn6SHJJ3dyfBmZjazKnvutwMXTmvbAGyPiFXA9jQPcBGwKt2GgVvaE9PMzOajaXGPiG8Bj09rXgtsTtObgUsa2j8TdfcDSyQtbVdYMzOrRhHRvJO0EtgWEWem+ScjYkmaFvBERCyRtA3YGBH3pWXbgWsjYucM6xymvndPrVZbMzIyMuvjT05O0tfXN8+n1nmHHj/MwWd6nWJmtUVkma3TufqXLV7wfXN9n+WaC/LNlmsuaG+2oaGhsYgYmGlZy8e5R0RIav4X4oX32wRsAhgYGIjBwcFZ+46OjjLX8l75+B1buGk8z1MF1vdPZZmt07n2XzG44Pvm+j7LNRfkmy3XXNC9bAs9WubgkeGW9PNQap8AVjT0W57azMysixZa3LcC69L0OmBLQ/s701Ez5wGHI+JAixnNzGyemn4+lnQnMAicIukx4APARuAuSVcBPwYuTd2/DFwM7AOeBt7VgcxmZtZE0+IeEZfPsuiCGfoGcHWroczMrDU+Q9XMrED5HU6RgapXIFzf3+EgZmYL5D13M7MCubibmRXIxd3MrEAec7cXpZm+V1nfP8WVM7T7vzvZ0ch77mZmBXJxNzMrkIu7mVmBXNzNzArk4m5mViAXdzOzArm4m5kVyMXdzKxALu5mZgXyGapmTVS9SqjPZLWceM/dzKxALu5mZgVycTczK5DH3K0oVcfHzUrXUnGXtB/4NfAcMBURA5JOBj4PrAT2A5dGxBOtxTQzs/lox7DMUESsjoiBNL8B2B4Rq4Dtad7MzLqoE2Pua4HNaXozcEkHHsPMzObQanEP4OuSxiQNp7ZaRBxI0z8Dai0+hpmZzZMiYuF3lpZFxISkVwD3An8FbI2IJQ19noiIk2a47zAwDFCr1daMjIzM+jiTk5P09fUtOOd8jU8crtSvtggOPtPhMAuUa7Zcc0Hr2fqXLW5fmAbdfv/PR67Zcs0F7c02NDQ01jAk/jwtFffnrUi6HpgE/gIYjIgDkpYCoxHx6rnuOzAwEDt37px1+ejoKIODg23JWUXVIy7W909x03ieBxzlmi3XXNB6tk6dodrt9/985Jot11zQ3mySZi3uCx6WkXSipJcfmQb+BNgNbAXWpW7rgC0LfQwzM1uYVnahasAXJR1Zz79FxFclfRu4S9JVwI+BS1uPaWZm87Hg4h4RPwJeN0P7L4ELWgnVKT7BxcxeLHz5ATOzArm4m5kVyMXdzKxALu5mZgVycTczK5CLu5lZgfI8VdCsYP6frNYN3nM3MyuQ99zN2sQnyVlOvOduZlYgF3czswJ5WMYsU0eGedb3T3HlHEM+/uLVZuI9dzOzArm4m5kVyMXdzKxALu5mZgVycTczK5CLu5lZgVzczcwK5OJuZlago/4kJl/Pw6waX43yxaVje+6SLpT0iKR9kjZ06nHMzOyFOrLnLukY4JPAm4DHgG9L2hoRD3fi8cxezPzp1WbSqWGZc4B9EfEjAEkjwFrAxd2sIOMTh+e87s0RL8ahntn+6E6/VlCnXhtFRPtXKr0duDAi/jzNvwM4NyLe29BnGBhOs68GHpljlacAv2h70NblmgvyzZZrLsg3W665IN9sueaC9mb7/Yg4daYFPftCNSI2AZuq9JW0MyIGOhxp3nLNBflmyzUX5Jst11yQb7Zcc0H3snXqC9UJYEXD/PLUZmZmXdCp4v5tYJWk0yQdD1wGbO3QY5mZ2TQdGZaJiClJ7wW+BhwD3BYRe1pYZaXhmx7INRfkmy3XXJBvtlxzQb7Zcs0FXcrWkS9Uzcyst3z5ATOzArm4m5kVKOvintMlDCTdJumQpN0NbSdLulfSD9LPk3qQa4WkHZIelrRH0jUZZXuppAclfS9luyG1nybpgbRdP5++dO86ScdI+q6kbZnl2i9pXNIuSTtTWw7bc4mkuyV9X9JeSa/PJNer02t15PYrSe/LJNvfpPf+bkl3pt+JrrzPsi3uDZcwuAg4A7hc0hk9jHQ7cOG0tg3A9ohYBWxP8902BayPiDOA84Cr0+uUQ7ZngfMj4nXAauBCSecBHwJujojTgSeAq3qQDeAaYG/DfC65AIYiYnXD8dA5bM+PAl+NiNcAr6P+2vU8V0Q8kl6r1cAa4Gngi73OJmkZ8NfAQEScSf3gksvo1vssIrK8Aa8HvtYwfx1wXY8zrQR2N8w/AixN00uBRzJ43bZQv6ZPVtmAlwHfAc6lfnbesTNt5y7mWU79F/58YBugHHKlx94PnDKtrafbE1gMPEo6CCOXXDPk/BPgv3LIBiwDfgqcTP3IxG3Am7v1Pst2z53fvTBHPJbaclKLiANp+mdArZdhJK0EzgIeIJNsaehjF3AIuBf4IfBkREylLr3arv8C/B3w2zT/e5nkAgjg65LG0mU6oPfb8zTg58Cn01DWv0o6MYNc010G3Jmme5otIiaADwM/AQ4Ah4ExuvQ+y7m4H1Wi/me4Z8eVSuoDvgC8LyJ+1bisl9ki4rmof1xeTv2Ccq/pRY5Gkv4UOBQRY73OMos3RsTZ1Ickr5b0R40Le7Q9jwXOBm6JiLOAp5g2zJHB78DxwFuBf5++rBfZ0hj/Wup/GF8JnMgLh3Y7JufifjRcwuCgpKUA6eehXoSQdBz1wn5HRNyTU7YjIuJJYAf1j6FLJB05ga4X2/UNwFsl7QdGqA/NfDSDXMD/7/EREYeojx2fQ++352PAYxHxQJq/m3qx73WuRhcB34mIg2m+19n+GHg0In4eEb8B7qH+3uvK+yzn4n40XMJgK7AuTa+jPt7dVZIE3ArsjYiPZJbtVElL0vQi6t8F7KVe5N/eq2wRcV1ELI+IldTfV9+MiCt6nQtA0omSXn5kmvoY8m56vD0j4mfATyW9OjVdQP0S3j1/nzW4nN8NyUDvs/0EOE/Sy9Lv6ZHXrDvvs15++VHhC4mLgf+hPk779z3Ocif1cbPfUN+LuYr6OO124AfAN4CTe5DrjdQ/bj4E7Eq3izPJ9ofAd1O23cA/pPY/AB4E9lH/CH1CD7frILAtl1wpw/fSbc+R930m23M1sDNtz/8ATsohV8p2IvBLYHFDW8+zATcA30/v/88CJ3TrfebLD5iZFSjnYRkzM1sgF3czswK5uJuZFcjF3cysQC7uZmYFcnE3MyuQi7uZWYH+D/rzNrG/2/6EAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nBjyeM7vMVy"
      },
      "source": [
        "max_seq_len = 25\n",
        "# Tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text,\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# Tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text,\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# Tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text,\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL6K2gNuvRc2"
      },
      "source": [
        "# Converting Integer Sequences to Tensor\n",
        "\n",
        "# For train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels)\n",
        "\n",
        "# For validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels)\n",
        "\n",
        "# For test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiHAXrtXvT9Z"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# Sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# DataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# Sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# DataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FapzQMuvWd5"
      },
      "source": [
        "# Freeze all the parameters\n",
        "for param in roberta.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcAr1VZ_vX7B"
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "class ROBERTA_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, roberta):\n",
        "      \n",
        "      super(ROBERTA_Arch, self).__init__()\n",
        "\n",
        "      self.roberta = roberta \n",
        "      \n",
        "      # Dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # Relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # Dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # Dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,3)\n",
        "\n",
        "      # Softmax activation function\n",
        "      self.softmax= nn.LogSoftmax(dim=1)\n",
        "\n",
        "\n",
        "    # Define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      # Pass the inputs to the model  \n",
        "      _, cls_hs = self.roberta(sent_id, attention_mask=mask)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # Output layer\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oDoBoYdvay8",
        "outputId": "d9c7b406-a56c-4e30-f4af-4cff2daa4adc"
      },
      "source": [
        "# Pass the pre-trained ROBERTA to our define architecture\n",
        "model = ROBERTA_Arch(roberta)\n",
        "\n",
        "# Push the model to GPU\n",
        "model = model.to(device)\n",
        "print (device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDNCxGHnvdL1"
      },
      "source": [
        "# Optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmRnhX3Yv2Pc",
        "outputId": "f1a1c5a8-eedb-48da-bd4b-21d1bd917999"
      },
      "source": [
        "# Finding class weights\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.29854255 0.53620656 2.74007937]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tjhQmsGv4_e"
      },
      "source": [
        "# Convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# Loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# Number of training epochs\n",
        "epochs = 10\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywnd2bQav7mS"
      },
      "source": [
        "# Function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # Empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # Iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # Progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # Push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # Clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # Get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # Compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # Add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # Backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # Append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # Compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # Predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # Reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  # Returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcOBTYhzv-jh"
      },
      "source": [
        "# Function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # Deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # Empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # Iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # Push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # Deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # Compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # Compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # Reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkVkTfzrwEPc",
        "outputId": "ac41422a-daa9-447d-9953-037802f13e3c"
      },
      "source": [
        "# Set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# Empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "# For each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    # Train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    # Evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    # Save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # Append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.109\n",
            "Validation Loss: 1.098\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.098\n",
            "Validation Loss: 1.091\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.091\n",
            "Validation Loss: 1.084\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.082\n",
            "Validation Loss: 1.076\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.081\n",
            "Validation Loss: 1.072\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.065\n",
            "Validation Loss: 1.062\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.040\n",
            "Validation Loss: 1.031\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.029\n",
            "Validation Loss: 1.022\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.010\n",
            "Validation Loss: 1.027\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of     87.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.997\n",
            "Validation Loss: 0.982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRxyA2YhwGxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef2e11f-bb27-45fa-a137-3fac225e8739"
      },
      "source": [
        "# Load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyilS2rAwWAJ"
      },
      "source": [
        "# Get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfnj-b-wwYyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f458cf-fcf2-4e8d-8a88-5da1fc94064f"
      },
      "source": [
        "# Model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.11      0.15        18\n",
            "           1       0.76      0.91      0.83        43\n",
            "           2       0.27      0.33      0.30         9\n",
            "\n",
            "    accuracy                           0.63        70\n",
            "   macro avg       0.43      0.45      0.43        70\n",
            "weighted avg       0.57      0.63      0.59        70\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "uLipc1l2wazm",
        "outputId": "17ad21b1-dbdf-430a-af7a-a132d46dc113"
      },
      "source": [
        "# Confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0  0   1  2\n",
              "row_0          \n",
              "0      2   9  7\n",
              "1      3  39  1\n",
              "2      3   3  3"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrVOeQPIwdse",
        "outputId": "ccbf6874-5f0c-4c71-d6f6-21022433cb51"
      },
      "source": [
        "print(len(preds))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFugKyQ0zx6r",
        "outputId": "4fb2dffa-a2a6-4382-f42a-ca28e043fa22"
      },
      "source": [
        "print(len(test_y))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE7trlzk1Dml",
        "outputId": "71372b52-0eac-4ca9-8cc4-42d87666bd0d"
      },
      "source": [
        "testy_list = test_y.tolist()\n",
        "print (testy_list)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfMjbpax1yIb",
        "outputId": "20f5dd4f-04b0-4847-eb90-67a858666bb3"
      },
      "source": [
        "preds_list = preds.tolist()\n",
        "print (preds_list)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 2, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1, 0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOQ-kdB414o6",
        "outputId": "6101f7e3-ec01-488a-e3bc-333e7bd1b2b4"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(testy_list, preds_list)\n",
        "\n",
        "#Printing per class accuracy\n",
        "print (100*matrix.diagonal()/matrix.sum(axis=1))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11.11111111 90.69767442 33.33333333]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}